{
  "name": "vs-code-autocomment",
  "displayName": "OpenAI Auto DocString",
  "repository" : "https://github.com/arunk140/vs-code-autocomment",
  "description": "Generate Docstrings for functions using the OpenAI API.",
  "version": "1.0.0",
  "engines": {
    "vscode": "^1.62.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [
    "onCommand:vs-code-autocomment.genCommentFrmSelection"
  ],
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
	    {
        "command": "vs-code-autocomment.genCommentFrmSelection",
        "title": "Generate DocString for Selection"
      }
    ],
	"menus": {
		"editor/context": [
		  {
        "when": "editorHasSelection && editorLangId =~ /^typescript$|^python$|^php$|^java$|^javascript$/",
        "command": "vs-code-autocomment.genCommentFrmSelection"
		  }
		]
	},
    "configuration": {
      "properties": {
        "vs-code-autocomment.openAI.key": {
          "type": "string",
          "description": "The OpenAI API uses API keys for authentication. Visit your Open AI API Keys page to retrieve the API key you'll use in your requests.",
          "default": null
        },
        "vs-code-autocomment.openAI.temperature": {
          "type": "number",
          "description": "Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.",
          "default": "0.9"
        },
        "vs-code-autocomment.general.appendPredefinedExamples": {
          "type": "boolean",
          "default": false,
          "description": "Enabling this will improve the accuracy of the output but will send more Input tokens (Preset Examples) to the Open AI API."
        },
        "vs-code-autocomment.openAI.engine": {
          "type": "string",
          "description": "The ID of the engine to use for this request.",
          "default": "davinci-codex",
          "enum": ["davinci-codex", "cushman-codex"],
          "enumDescriptions": [
            "Most capable Codex model. Particularly good at translating natural language to code.",
            "Almost as capable as Davinci Codex, but slightly faster. This speed advantage may make it preferable for real-time applications."
          ]
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "pretest": "npm run compile && npm run lint",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js"
  },
  "devDependencies": {
    "@types/glob": "^7.1.4",
    "@types/mocha": "^9.0.0",
    "@types/node": "14.x",
    "@types/vscode": "^1.62.0",
    "@typescript-eslint/eslint-plugin": "^5.1.0",
    "@typescript-eslint/parser": "^5.1.0",
    "@vscode/test-electron": "^1.6.2",
    "eslint": "^8.1.0",
    "glob": "^7.1.7",
    "mocha": "^9.1.3",
    "typescript": "^4.4.4"
  },
  "dependencies": {
    "axios": "^0.24.0"
  }
}
